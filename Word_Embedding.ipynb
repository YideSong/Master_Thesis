{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\songi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\songi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "import nltk\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import gensim\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------Example of citations and its length:---------------\n2191\nThese problems formulations are similar to those studied in  and ; , respectively\n------------Example of citations with contexts and its length:------------\n2191\nThe second instantiation finds the borders of phrases beginning and end and then pairs them in an optimal way into different phrases These problems formulations are similar to those studied in  and ; , respectively The experimental results presented using the SNoW based approach compare favorably with previously published results, both for NPs and SV phrases A s important, we present a few experiments that shed light on some of the issues involved in using learned predictors that interact to produce the desired inference\n------------Example of citations with contexts and preprocessing and its length:------------\n2191\nthe second instantiation finds the borders of phrases beginning and end and then pairs them in an optimal way into different phrases these problems formulations are similar to those studied in and respectively the experimental results presented using the snow based approach compare favorably with previously published results both for nps and sv phrases important we present few experiments that shed light on some of the issues involved in using learned predictors that interact to produce the desired inference\n"
     ]
    }
   ],
   "source": [
    "#read preprocessed data from local\n",
    "with open('./Pickle_Data/citation_with_context.pk', 'rb') as f:\n",
    "    texts_with_context = pickle.load(f)\n",
    "#    print(texts_with_context)\n",
    "with open('./Pickle_Data/pre_citation_with_context.pk', 'rb') as f:\n",
    "    pre_texts_with_context = pickle.load(f)\n",
    "#    print(pre_texts_with_context)\n",
    "with open('./Pickle_Data/citation.pk', 'rb') as f:\n",
    "    texts = pickle.load(f)\n",
    "#    print(texts)\n",
    "with open('./Pickle_Data/polarities.pk', 'rb') as f:\n",
    "    polarities = pickle.load(f)\n",
    "#    print(polarities)\n",
    "with open('./Pickle_Data/purposes.pk', 'rb') as f:\n",
    "    purposes = pickle.load(f)\n",
    "#    print(purposes)\n",
    "\n",
    "citation_X = texts\n",
    "citation_with_context_X = texts_with_context\n",
    "pre_citation_with_context_X = pre_texts_with_context\n",
    "polarity_Y = polarities\n",
    "purpose_Y = purposes\n",
    "\n",
    "citation_X = np.asarray(citation_X)\n",
    "citation_with_context_X = np.asarray(citation_with_context_X)\n",
    "pre_citation_with_context_X = np.asarray(pre_citation_with_context_X)\n",
    "#print(citation_X)\n",
    "print(\"------------Example of citations and its length:---------------\")\n",
    "print(len(citation_X))\n",
    "print(citation_X[0])\n",
    "print(\"------------Example of citations with contexts and its length:------------\")\n",
    "print(len(citation_with_context_X))\n",
    "print(citation_with_context_X[0])\n",
    "print(\"------------Example of citations with contexts and preprocessing and its length:------------\")\n",
    "print(len(pre_citation_with_context_X))\n",
    "print(pre_citation_with_context_X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------INFO: word2vec model is loaded----------------\n"
     ]
    }
   ],
   "source": [
    "model = KeyedVectors.load('word2vec.model')\n",
    "print(\"----------------INFO: word2vec model is loaded----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\songi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('algorithm', 0.8449932336807251), ('algorithmic', 0.719566822052002), ('mathematical_algorithms', 0.6391038298606873), ('algorithmically', 0.6338590383529663), ('Algorithms', 0.6307376623153687), ('mathematical_algorithm', 0.623949408531189), ('mathematical_models', 0.6149172186851501), ('computational_algorithms', 0.6090747714042664), ('optimization_algorithms', 0.6071847081184387), ('proprietary_algorithms', 0.5949397683143616)]\n300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cats', 0.8099379539489746), ('dog', 0.7609456777572632), ('kitten', 0.7464985251426697), ('feline', 0.7326233983039856), ('beagle', 0.7150583267211914), ('puppy', 0.7075453996658325), ('pup', 0.6934291124343872), ('pet', 0.6891531348228455), ('felines', 0.6755931377410889), ('chihuahua', 0.6709762215614319)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('analyzes', 0.7746602296829224), ('statistical_analysis', 0.6847716569900513), ('Analysis', 0.6558783054351807), ('econometric_analysis', 0.603839635848999), ('assessment', 0.5894891023635864), ('anaylsis', 0.5846796035766602), ('analyis', 0.5808142423629761), ('analytical', 0.5791622996330261), ('evaluation', 0.5724815726280212), ('analyzed', 0.5600607991218567)]\n0.20410156\n0.2578125\n-0.111816406\n0.05444336\n"
     ]
    }
   ],
   "source": [
    "print(model.most_similar('algorithms'))\n",
    "print(len(model['algorithms']))\n",
    "print(model.most_similar('cat'))\n",
    "print(model.most_similar('analysis'))\n",
    "#print(model['citation'])\n",
    "print(model['cat'][1])\n",
    "print(model['cats'][1])\n",
    "print(model['CAT'][1])\n",
    "print(model['Cat'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate vector for a example sentence: Hallo I'm Yide\n['Hallo', 'I', \"'m\", 'Yide']\n300\n[ 8.68072510e-02 -2.07901001e-02  4.37622070e-02  6.29577637e-02\n -1.70898438e-02  7.50579834e-02 -1.89590454e-03 -6.03027344e-02\n  7.88574219e-02  7.54699707e-02 -3.47709656e-03 -9.82990265e-02\n -5.16510010e-02 -1.14746094e-01 -1.58569336e-01  9.86938477e-02\n  2.44140625e-04  2.09655762e-01  1.56250000e-02 -6.50634766e-02\n -7.50732422e-03  1.56127930e-01  1.97570801e-01 -1.11083984e-02\n  4.80957031e-02 -2.22854614e-02 -1.56616211e-01 -1.13525391e-02\n  1.87377930e-02 -8.88977051e-02  3.02734375e-02  6.90307617e-02\n -7.77587891e-02  1.61666870e-02  4.13208008e-02  3.45458984e-02\n -1.20220184e-02  1.31225586e-01  1.20193481e-01  7.70263672e-02\n  1.41418457e-01 -1.24023438e-01  1.93847656e-01  5.81665039e-02\n  4.71191406e-02  3.66210938e-03 -1.41204834e-01 -4.62646484e-02\n -8.43811035e-03  2.14947462e-02 -3.32031250e-02  2.08251953e-01\n  1.80236816e-01  7.18078613e-02  8.58459473e-02  9.58557129e-02\n -3.69262695e-02 -4.85229492e-02  7.65075684e-02 -1.22436523e-01\n  3.41491699e-02  5.85174561e-02 -1.37084961e-01  3.24249268e-02\n  5.23681641e-02 -1.13403320e-01 -1.09252930e-01  1.23962402e-01\n -1.79443359e-02  1.20330811e-01  1.16699219e-01  1.15524292e-01\n  5.40695190e-02 -4.88281250e-04 -2.68005371e-01 -9.32006836e-02\n  1.02798462e-01 -8.05130005e-02  1.86676025e-01  1.78894043e-01\n  3.93676758e-03 -1.05224609e-01  1.36077881e-01 -8.17871094e-03\n -1.27197266e-01 -6.80541992e-03 -2.87170410e-02  2.02392578e-01\n  1.15695953e-01  9.62219238e-02 -6.40869141e-02  3.99780273e-02\n -1.21032715e-01 -1.44348145e-02 -2.30468750e-01  6.28356934e-02\n  1.62109375e-01  9.60769653e-02  8.17260742e-02 -8.16040039e-02\n -1.67480469e-01 -1.28295898e-01 -5.81932068e-02  4.79125977e-03\n -3.83605957e-02  1.30935669e-01 -2.96936035e-02  4.02832031e-03\n  3.77502441e-02 -1.13098145e-01 -1.38916016e-01 -1.11267090e-01\n  1.87927246e-01  2.09960938e-02 -1.81274414e-02 -1.01226807e-01\n -1.14624023e-01 -2.28759766e-01  1.37849808e-01 -9.66796875e-02\n -2.84805298e-02  1.48925781e-02 -1.59393311e-01  1.54693604e-01\n  4.13208008e-02 -4.05273438e-02 -7.71484375e-02  2.18505859e-02\n -7.45849609e-02 -3.10058594e-02 -2.86254883e-01 -4.30908203e-02\n -1.61071777e-01 -2.68554688e-03 -1.79199219e-01 -7.14111328e-03\n -9.02709961e-02  1.24755859e-01  1.03118896e-01  1.40518188e-01\n  9.22546387e-02  4.53491211e-02  2.02026367e-02 -3.81469727e-02\n  1.80664062e-02  3.71856689e-02 -5.07812500e-02 -9.83886719e-02\n -7.20214844e-02 -9.46807861e-02  6.82144165e-02  1.07177734e-01\n -5.81054688e-02 -1.79443359e-02 -3.13110352e-02  3.18603516e-02\n  2.57873535e-02  3.55834961e-02 -1.20315552e-01  1.67236328e-02\n -1.35803223e-02  5.85327148e-02 -6.46972656e-03  2.32910156e-01\n  3.81851196e-02 -1.25579834e-01  7.62023926e-02  1.96990967e-02\n  7.67822266e-02 -3.48052979e-02 -1.65084839e-01 -3.35693359e-04\n  9.21630859e-02 -1.16943359e-01 -1.36230469e-01  1.11541748e-01\n  1.24851227e-01 -1.04919434e-01  4.29687500e-02  3.53698730e-02\n -7.26928711e-02 -2.52380371e-02  4.10156250e-02  1.23016357e-01\n  2.46582031e-02  1.36718750e-02 -1.95922852e-02  4.88891602e-02\n -4.26635742e-02 -2.23999023e-02 -4.01048660e-02  6.93359375e-02\n -3.37219238e-02  3.60717773e-02  4.82788086e-02  8.34350586e-02\n -3.19824219e-02 -6.18591309e-02 -1.44104004e-01 -8.60595703e-02\n -8.17565918e-02 -1.40380859e-02  3.52783203e-02  2.00195312e-02\n -8.67919922e-02  3.14941406e-02 -1.18175507e-01 -1.81579590e-02\n -1.15600586e-01  1.71997070e-01  2.49023438e-02 -5.45654297e-02\n -4.73022461e-02  5.69801331e-02 -1.15356445e-01 -7.08608627e-02\n  1.17431641e-01 -7.46459961e-02 -3.63769531e-02 -1.27197266e-01\n -8.60595703e-02  1.92260742e-02 -1.12609863e-01 -1.75170898e-02\n  1.58508301e-01 -2.29980469e-01  1.58386230e-02 -7.87506104e-02\n -1.61865234e-01 -2.78511047e-02  1.84173584e-02 -7.34863281e-02\n -1.81976318e-01  3.47595215e-02  4.51049805e-02  2.36206055e-02\n -7.27539062e-02  1.57409668e-01  9.88159180e-02  2.77099609e-02\n  2.70204544e-02  7.35473633e-02  3.73535156e-02  1.28784180e-02\n -5.00488281e-02 -6.23779297e-02 -1.22558594e-01  1.58599854e-01\n  2.56347656e-03 -9.45434570e-02  6.77490234e-03 -4.92858887e-02\n  3.72314453e-02  1.65893555e-01  2.27661133e-02  2.54211426e-02\n -4.67681885e-03 -8.48846436e-02 -1.61743164e-01 -1.21223450e-01\n -4.73632812e-02  5.33447266e-02  8.46557617e-02 -1.03820801e-01\n  5.60302734e-02  1.64062500e-01 -5.00793457e-02  1.06201172e-02\n -6.59179688e-02  7.55004883e-02 -9.03320312e-03  6.37817383e-02\n  1.32080078e-01  1.01350784e-01  1.25427246e-02 -4.44641113e-02\n -6.19201660e-02 -2.10144043e-01 -9.23919678e-02 -8.55712891e-02\n  2.74505615e-02  2.10971832e-02 -2.99682617e-02 -1.53656006e-02\n  1.44348145e-01  1.46911621e-01 -8.03222656e-02 -1.16943359e-01\n -1.13037109e-01  1.13639832e-01 -5.99975586e-02  7.48901367e-02\n -1.33651733e-01 -1.33056641e-02 -5.63964844e-02 -7.51953125e-02\n -8.23974609e-02  1.27105713e-02  7.69042969e-02  2.31323242e-02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\songi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# Calculate vector for a example sentence\n",
    "example_sentence = \"Hallo I'm Yide\"\n",
    "print(\"Calculate vector for a example sentence: \" + example_sentence)\n",
    "token_sen = nltk.word_tokenize(example_sentence)\n",
    "print(token_sen)\n",
    "\n",
    "sen_len = 0\n",
    "a = np.zeros(300)\n",
    "for token in token_sen:\n",
    "    if token in model.wv.vocab:\n",
    "        sen_len = sen_len + 1\n",
    "        a = a + model[token]\n",
    "        #print(model[token][0])\n",
    "print(len(a))\n",
    "a =a/sen_len\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\songi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\songi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in true_divide\n  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Number of citations converted to vectors: ------------\n2191\n"
     ]
    }
   ],
   "source": [
    "# Calculate for each citation (whiout contexts) a Vector, save those vectors in a List -> vector_citations_X\n",
    "vector_citations_X = []\n",
    "for sen in citation_X:\n",
    "    #Todo: try to use other tokenize methods\n",
    "    token_sen = nltk.word_tokenize(sen)\n",
    "    sen_len = 0\n",
    "    vec_sen = np.zeros(300)\n",
    "    for token in token_sen:\n",
    "        if token in model.wv.vocab:\n",
    "            sen_len = sen_len + 1\n",
    "            vec_sen = vec_sen + model[token]\n",
    "    #print(len(vec_sen))\n",
    "    vec_sen = vec_sen / sen_len\n",
    "    vector_citations_X.append(vec_sen)\n",
    "print(\"--------Number of citations converted to vectors: ------------\")\n",
    "print(len(vector_citations_X))\n",
    "#print(\"-------Example vector for first citation: --------------------\")\n",
    "#print(vector_citations_X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\songi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Number of citations converted to vectors: ------------\n2191\n"
     ]
    }
   ],
   "source": [
    "# Calculate for each citations (with contexts) a Vector, save those vectors in a List -> vector_citation_with_contexts_X\n",
    "vector_citation_with_contexts_X = []\n",
    "for sen in citation_with_context_X:\n",
    "    token_sen = nltk.word_tokenize(sen)\n",
    "    sen_len = 0\n",
    "    vec_sen = np.zeros(300)\n",
    "    for token in token_sen:\n",
    "        if token in model.wv.vocab:\n",
    "            sen_len = sen_len + 1\n",
    "            vec_sen = vec_sen + model[token]\n",
    "    #print(len(vec_sen))\n",
    "    vec_sen = vec_sen / sen_len\n",
    "    vector_citation_with_contexts_X.append(vec_sen)\n",
    "print(\"--------Number of citations converted to vectors: ------------\")\n",
    "print(len(vector_citation_with_contexts_X))\n",
    "#print(\"-------Example vector for first citation: --------------------\")\n",
    "#print(vector_citation_with_contexts_X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\songi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Number of citations converted to vectors: ------------\n2191\n"
     ]
    }
   ],
   "source": [
    "# Calculate for each citations (with contexts and preprocessing) a Vector, save those vectors in a List -> vector_citation_with_contexts_X\n",
    "vector_pre_citation_with_contexts_X = []\n",
    "for sen in pre_citation_with_context_X:\n",
    "    token_sen = nltk.word_tokenize(sen)\n",
    "    sen_len = 0\n",
    "    vec_sen = np.zeros(300)\n",
    "    for token in token_sen:\n",
    "        if token in model.wv.vocab:\n",
    "            sen_len = sen_len + 1\n",
    "            vec_sen = vec_sen + model[token]\n",
    "    #print(len(vec_sen))\n",
    "    vec_sen = vec_sen / sen_len\n",
    "    vector_pre_citation_with_contexts_X.append(vec_sen)\n",
    "print(\"--------Number of citations converted to vectors: ------------\")\n",
    "print(len(vector_citation_with_contexts_X))\n",
    "#print(\"-------Example vector for first citation: --------------------\")\n",
    "#print(vector_citation_with_contexts_X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Vectors saved in local------------\n"
     ]
    }
   ],
   "source": [
    "# Save vectors of each citations to local.\n",
    "with open('./Pickle_Data/citation_vec.pk', 'wb') as f:\n",
    "    pickle.dump(vector_citations_X, f)\n",
    "# with open('C:/Users/songi/PycharmProjects/MasterThesis/citation_vec.pk', 'rb') as f:\n",
    "#     data = pickle.load(f)\n",
    "#     print(data[0])\n",
    "print(\"--------Vectors saved in local------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Vectors saved in local------------\n"
     ]
    }
   ],
   "source": [
    "# Save vectors of each citations (with contexts) to local.\n",
    "with open('./Pickle_Data/citation_with_context_vec.pk', 'wb') as f:\n",
    "    pickle.dump(vector_citation_with_contexts_X, f)\n",
    "# with open('C:/Users/songi/PycharmProjects/MasterThesis/citation_with_context_vec.pk', 'rb') as f:\n",
    "#     data = pickle.load(f)\n",
    "#     print(data[0])\n",
    "print(\"--------Vectors saved in local------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Vectors saved in local------------\n"
     ]
    }
   ],
   "source": [
    "# Save vectors of each citations (with contexts) to local.\n",
    "with open('./Pickle_Data/pre_citation_with_context_vec.pk', 'wb') as f:\n",
    "    pickle.dump(vector_pre_citation_with_contexts_X, f)\n",
    "# with open('C:/Users/songi/PycharmProjects/MasterThesis/citation_with_context_vec.pk', 'rb') as f:\n",
    "#     data = pickle.load(f)\n",
    "#     print(data[0])\n",
    "print(\"--------Vectors saved in local------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}