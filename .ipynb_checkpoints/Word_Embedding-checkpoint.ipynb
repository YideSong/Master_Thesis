{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import nltk\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import gensim\n",
    "\n",
    "\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['These problems formulations are similar to those studied in <REF>Ramshaw and Marcus, 1995</REF> and <TREF>Church, 1988</TREF>; <REF>Argamon et al , 1998</REF>, respectively'\n",
      " 'This approach has been studied in <TREF>Church, 1988</TREF>; <REF>Argamon et al , 1998</REF>'\n",
      " 'The observation that shallow syntactic information can be extracted using local information by examining the pattern itself, its nearby context and the local part-of-speech information has motivated the use of learning methods to recognize these patterns <TREF>Church, 1988</TREF>; <REF>Ramshaw and Marcus, 1995</REF>; <REF>Argamon et al , 1998</REF>; <REF>Cardie and Pierce, 1998</REF>'\n",
      " ...\n",
      " 'The results we report are with the Gaussian prior regularization term described in <TREF>Johnson et al , 1999</TREF>'\n",
      " 'We used these parses as the input to a MaxEnt reranker <TREF>Johnson et al , 1999</TREF>; <REF>Riezler et al , 2002</REF> that selects the best parse from the set of parses for each sentence, obtaining an f-score of 910 on sentences of length 100 or less'\n",
      " 'Previous studies <REF>Abney, 1997</REF>; <TREF>Johnson et al , 1999</TREF>; <REF>Riezler et al , 2000</REF>; <REF>Miyao et al , 2003</REF>; Malouf and van <REF>Noord, 2004</REF>; <REF>Kaplan et al , 2004</REF>; <REF>Miyao and Tsujii, 2005</REF> defined a probabilistic model of unification-based grammars as a log-linear model or maximum entropy model <REF>Berger et al , 1996</REF>']\n"
     ]
    }
   ],
   "source": [
    "texts_polarities = []\n",
    "texts_purposes = []\n",
    "texts = []\n",
    "polarities = []\n",
    "purposes = []\n",
    "polarities2 = []\n",
    "purposes2 = []\n",
    "data_number = 0\n",
    "polarity_information = {\"positive\": 0, \"neutral\": 0, \"negative\": 0}\n",
    "purpose_information = {\"Criticizing\": 0, \"Comparison\": 0, \"Use\": 0, \"Substantiating\": 0, \"Basis\": 0, \"Neutral\": 0}\n",
    "\n",
    "# import data\n",
    "for line in codecs.open(\"./annotated_sentences.txt\", \"r\", \"utf-8\", 'ignore').readlines():\n",
    "    data_number = data_number + 1\n",
    "    parts = line.split('\\t')\n",
    "    if parts[12].strip() != \"0\":\n",
    "        texts_polarities.append(parts[5])\n",
    "        polarities.append(parts[12].strip())\n",
    "    if parts[11].strip() != \"0\":\n",
    "        texts_purposes.append(parts[5])\n",
    "        purposes.append(parts[11].strip())\n",
    "    if parts[11].strip() != \"0\" and parts[12].strip() != \"0\":\n",
    "        texts.append(parts[5])\n",
    "        purposes2.append(int(parts[11].strip()))\n",
    "        polarities2.append(int(parts[12].strip()))\n",
    "\n",
    "\n",
    "\n",
    "citation_X = texts\n",
    "polarity_y = polarities2\n",
    "purpose_y = purposes2\n",
    "\n",
    "citation_X = np.asarray(citation_X)\n",
    "print(citation_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\songi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('algorithm', 0.8449932336807251), ('algorithmic', 0.719566822052002), ('mathematical_algorithms', 0.6391038298606873), ('algorithmically', 0.6338590383529663), ('Algorithms', 0.6307376623153687), ('mathematical_algorithm', 0.623949408531189), ('mathematical_models', 0.6149172186851501), ('computational_algorithms', 0.6090747714042664), ('optimization_algorithms', 0.6071847081184387), ('proprietary_algorithms', 0.5949397683143616)]\n",
      "300\n",
      "[('cats', 0.8099379539489746), ('dog', 0.7609456777572632), ('kitten', 0.7464985251426697), ('feline', 0.7326233983039856), ('beagle', 0.7150583267211914), ('puppy', 0.7075453996658325), ('pup', 0.6934291124343872), ('pet', 0.6891531348228455), ('felines', 0.6755931377410889), ('chihuahua', 0.6709762215614319)]\n"
     ]
    }
   ],
   "source": [
    "model = KeyedVectors.load('word2vec.model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\songi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('algorithm', 0.8449932336807251), ('algorithmic', 0.719566822052002), ('mathematical_algorithms', 0.6391038298606873), ('algorithmically', 0.6338590383529663), ('Algorithms', 0.6307376623153687), ('mathematical_algorithm', 0.623949408531189), ('mathematical_models', 0.6149172186851501), ('computational_algorithms', 0.6090747714042664), ('optimization_algorithms', 0.6071847081184387), ('proprietary_algorithms', 0.5949397683143616)]\n",
      "300\n",
      "[('cats', 0.8099379539489746), ('dog', 0.7609456777572632), ('kitten', 0.7464985251426697), ('feline', 0.7326233983039856), ('beagle', 0.7150583267211914), ('puppy', 0.7075453996658325), ('pup', 0.6934291124343872), ('pet', 0.6891531348228455), ('felines', 0.6755931377410889), ('chihuahua', 0.6709762215614319)]\n"
     ]
    }
   ],
   "source": [
    "print(model.most_similar('algorithms'))\n",
    "print(len(model['algorithms']))\n",
    "print(model.most_similar('cat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\songi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cats', 0.8099379539489746), ('dog', 0.7609456777572632), ('kitten', 0.7464985251426697), ('feline', 0.7326233983039856), ('beagle', 0.7150583267211914), ('puppy', 0.7075453996658325), ('pup', 0.6934291124343872), ('pet', 0.6891531348228455), ('felines', 0.6755931377410889), ('chihuahua', 0.6709762215614319)]\n"
     ]
    }
   ],
   "source": [
    "print(model.most_similar('cat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-beb6e0e468ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'algorithms'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "print(model['algorithms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KeyedVectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-f0055841c452>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'word2vec.model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'algorithms'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'KeyedVectors' is not defined"
     ]
    }
   ],
   "source": [
    "model = KeyedVectors.load('word2vec.model')\n",
    "print(model['algorithms'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
